{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Auxiliar_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc31fde107e647469506dafa23f5e217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92d1b7e897af41c2b425a085bb021bc3",
              "IPY_MODEL_528acb9d62d0497f914e9579a5aee7b5",
              "IPY_MODEL_7d22c1c975f643e0ae891ab6473e4a3b"
            ],
            "layout": "IPY_MODEL_1496c76aeb0f4b8696278a4ed0cde7f8"
          }
        },
        "92d1b7e897af41c2b425a085bb021bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56312748ca634f828791ec8265aa7876",
            "placeholder": "​",
            "style": "IPY_MODEL_46f9f59c8a9c453d802f416571ec22d5",
            "value": "Downloading: 100%"
          }
        },
        "528acb9d62d0497f914e9579a5aee7b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_925e7715f0b74b4ab052be3e5470b8e5",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4054bc0034db41499fff08594ccb5077",
            "value": 231508
          }
        },
        "7d22c1c975f643e0ae891ab6473e4a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3f089cadbc64b309452463746a06958",
            "placeholder": "​",
            "style": "IPY_MODEL_5184fbef127a4956aad274267124b5a6",
            "value": " 226k/226k [00:00&lt;00:00, 4.40MB/s]"
          }
        },
        "1496c76aeb0f4b8696278a4ed0cde7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56312748ca634f828791ec8265aa7876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f9f59c8a9c453d802f416571ec22d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "925e7715f0b74b4ab052be3e5470b8e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4054bc0034db41499fff08594ccb5077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3f089cadbc64b309452463746a06958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5184fbef127a4956aad274267124b5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3628ccbff98143cbb7c74d051fd4545a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89f2d30b17d44c4ba3eae840aac3275e",
              "IPY_MODEL_bc0e3c997e1040bbb32ab0f7337d8367",
              "IPY_MODEL_1ad17b7acf7d4fdb82813faf7f323f56"
            ],
            "layout": "IPY_MODEL_b71f158b74a04b39a93fe2dbb9565665"
          }
        },
        "89f2d30b17d44c4ba3eae840aac3275e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0de343dd5d61415bba8f9bacc9b9014a",
            "placeholder": "​",
            "style": "IPY_MODEL_245b4bb7f82b4e87840b79e930cb5bb9",
            "value": "Downloading: 100%"
          }
        },
        "bc0e3c997e1040bbb32ab0f7337d8367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06d8a4a8586746cba2f97b7e5bc4923b",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2c5de2a1d1641f59dc828adb8d4f916",
            "value": 28
          }
        },
        "1ad17b7acf7d4fdb82813faf7f323f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eafc821b115e41549abc20876ed50d41",
            "placeholder": "​",
            "style": "IPY_MODEL_3016eb9b17274257b388e3fa416293e2",
            "value": " 28.0/28.0 [00:00&lt;00:00, 983B/s]"
          }
        },
        "b71f158b74a04b39a93fe2dbb9565665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0de343dd5d61415bba8f9bacc9b9014a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "245b4bb7f82b4e87840b79e930cb5bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06d8a4a8586746cba2f97b7e5bc4923b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c5de2a1d1641f59dc828adb8d4f916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eafc821b115e41549abc20876ed50d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3016eb9b17274257b388e3fa416293e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a229bd6b3a848a89f0f1ef51fc35aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05592fe8dc854e9b80677a05e08a6793",
              "IPY_MODEL_7812e46862374d179bb2e982c7ba4fd9",
              "IPY_MODEL_acd09034fd9d48a1a3214ff40a048c5f"
            ],
            "layout": "IPY_MODEL_30025d31d0fa437391a7c1b06255a76e"
          }
        },
        "05592fe8dc854e9b80677a05e08a6793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a97c2f4ba38248c3826f7d9906ce2577",
            "placeholder": "​",
            "style": "IPY_MODEL_8aae1e86310e43bc812e38aafaef75e0",
            "value": "Downloading: 100%"
          }
        },
        "7812e46862374d179bb2e982c7ba4fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad56a032ccea4a55bdfc412ade9097c8",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f00921616e345cd81334406a0c5f5c2",
            "value": 570
          }
        },
        "acd09034fd9d48a1a3214ff40a048c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17fa96c0a7404965b91d8039a8d6ee59",
            "placeholder": "​",
            "style": "IPY_MODEL_66fe3b76d3a04227a65ab03a301ffc1d",
            "value": " 570/570 [00:00&lt;00:00, 17.3kB/s]"
          }
        },
        "30025d31d0fa437391a7c1b06255a76e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97c2f4ba38248c3826f7d9906ce2577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aae1e86310e43bc812e38aafaef75e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad56a032ccea4a55bdfc412ade9097c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f00921616e345cd81334406a0c5f5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17fa96c0a7404965b91d8039a8d6ee59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66fe3b76d3a04227a65ab03a301ffc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6abdf39855a94856aef23f01abded812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ad6d079e67c4ec281a95d7c8b27c749",
              "IPY_MODEL_bfc2ddc5257643ec95fcff86bce90903",
              "IPY_MODEL_45f16e7245d54b579924dd981f173d94"
            ],
            "layout": "IPY_MODEL_3e8f2fca0aa442388b654527960d1421"
          }
        },
        "2ad6d079e67c4ec281a95d7c8b27c749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f03663eb0d4ca5b3daad423068426d",
            "placeholder": "​",
            "style": "IPY_MODEL_c2c3b26cda834b24b1b53f15318d1742",
            "value": "Downloading: 100%"
          }
        },
        "bfc2ddc5257643ec95fcff86bce90903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d289880dfa2744ae97824cfb75de490a",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a7e8a9c38164ea2aa3d7705900ccf91",
            "value": 440473133
          }
        },
        "45f16e7245d54b579924dd981f173d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7d0a4db1cf4c8497dcb279fb0fc2a5",
            "placeholder": "​",
            "style": "IPY_MODEL_1bbe16479559429c97d9e99a7ad326cf",
            "value": " 420M/420M [00:07&lt;00:00, 60.6MB/s]"
          }
        },
        "3e8f2fca0aa442388b654527960d1421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f03663eb0d4ca5b3daad423068426d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c3b26cda834b24b1b53f15318d1742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d289880dfa2744ae97824cfb75de490a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a7e8a9c38164ea2aa3d7705900ccf91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f7d0a4db1cf4c8497dcb279fb0fc2a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bbe16479559429c97d9e99a7ad326cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLLTxJRSwscP"
      },
      "source": [
        "#Introducción\n",
        "\n",
        "<!-- Aquí la idea es mostrarles como pueden usar BERT y quizás BETO en\n",
        "español usando la librería Transformers. Me interesa que lo usen\n",
        "de dos formas:\n",
        "\n",
        "1) como extractor de vectores contextualizados\n",
        "\n",
        "2) para hacer fine-tuning a otra task (e.g., Question Answering).\n",
        " -->\n",
        "\n",
        "\n",
        "------------------------------------------------------\n",
        "En esta auxiliar vamos a utilizar BERT, un modelo de lenguaje desarrollado por Google. Este modelo rompió varios récords en NLP y de hecho, cada vez que buscan en Google, BERT ayuda a refinar sus búsquedas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2EvTlRNbfSV"
      },
      "source": [
        "## Pero, qué es BERT?\n",
        "\n",
        "BERT es un personaje de plaza sésamo, al igual que ELMo, los cuales saben mucho de lenguaje y podemos ver con una mirada desafiante en la siguiente imagen:\n",
        "\n",
        "![bert y elmo](https://i.imgur.com/1T4kyrq.png)\n",
        "\n",
        "Los genios dándole nombres a los papers decidieron que era buena idea que los acrónimos se refirieran a los personajes de plaza sesamo, con los cuales algunos de nosotros (los más viejos) aprendimos a hablar y deletrear ~~hasta quizás mejor que en el jardín infantil~~. Al igual que Elmo, Embeddings from Language MOdels, BERT es el acrónimo de Bidirectional Encoder Representations from Transformers. \\\n",
        "Estos dos modelos producen \"contextualized word embeddings\". A diferencia de los modelos que producen static word embeddings como Word2Vec, la representación no depende solo de la palabra, sino que de la palabra y su contexto. Por lo tanto, cada palabra tiene infinitas representaciones, lo cual es mucho más flexible que tener solo un vector para cada palabra.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woZQw3j2bkPw"
      },
      "source": [
        "## Qué significa Bidirectional Encoder Representations from Transformers?\n",
        "A diferencia de ELMo, el cual era una concatenación de información de izquierda-derecha y derecha-izquierda, BERT es bidireccional, es decir, toma en cuenta los contextos a la izquierda y derecha de la palabra simultáneamente.\n",
        "\n",
        "BERT además utiliza Transformers, arquitecturas de deep learning altamente paralelizables que cuentan con un proceso de Encoder-Decoder. Dado que el objetivo de BERT es generar un modelo de lenguaje, solo es necesario el mecanismo de Encoding y le dejan el proceso de Decoding a las distintas tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-CrbVL5bsrm"
      },
      "source": [
        "## Y como fue entrenado?\n",
        "\n",
        "El primer objetivo de BERT es algo que se llama \"masked language modeling\". En este modelo, las palabras de una frase se borran al azar y se reemplazan por un token especial ([MASK]) con probabilidad 15%. Luego, se utiliza un Transformer para generar una predicción para la palabra remplazada por [MASK] basada en las palabras no enmascaradas que la rodean, tanto a la izquierda como a la derecha.\n",
        "\n",
        "El segundo objetivo de BERT es resolver la tarea de Next Sentence Prediction. El modelo recibe dos oraciones como entrada y aprende a predecir si la segunda oración del par es la oración que siguiente del documento original. Durante el entrenamiento, el 50% de los inputs son un par en el que la segunda frase es la frase siguiente en el documento original, mientras que en el otro 50% se elige una frase aleatoria del corpus como segunda frase.\n",
        "\n",
        "\n",
        "Pueden leer un poco más [acá](http://mlexplained.com/2019/01/07/paper-dissected-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding-explained/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqCm5gsibx5s"
      },
      "source": [
        "\n",
        "\n",
        "## Oye, pero esto suena un poco magico, tienes algunos ejemplos?\n",
        "\n",
        "Hay bastantes librerías que tienen el modelo pre-entrenado a disposición, partiendo por el [GitHub de BERT](https://github.com/google-research/bert) implementado en TensorFlow. Como nosotros sabemos utilizar pytorch, utilizaremos la [version de HuggingFace](https://huggingface.co/transformers/) la cual es respaldada por el github de Google y la elogian: \"which is compatible with our pre-trained checkpoints and is able to reproduce our results\". Esta version se importa con la libreria transformers. Otras version disponibles son [sentence-bert](https://github.com/UKPLab/sentence-transformers) o [bert-as-service](https://github.com/hanxiao/bert-as-service)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXbAJvFZdRK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2090ea-32a1-43d0-ff1a-fc9fe03dddac"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 34.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsaS37KAzZoj"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcHpz3iEc6-_"
      },
      "source": [
        "Veamos el primer ejemplo que entrega la documentación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HePHI6odsBc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "bc31fde107e647469506dafa23f5e217",
            "92d1b7e897af41c2b425a085bb021bc3",
            "528acb9d62d0497f914e9579a5aee7b5",
            "7d22c1c975f643e0ae891ab6473e4a3b",
            "1496c76aeb0f4b8696278a4ed0cde7f8",
            "56312748ca634f828791ec8265aa7876",
            "46f9f59c8a9c453d802f416571ec22d5",
            "925e7715f0b74b4ab052be3e5470b8e5",
            "4054bc0034db41499fff08594ccb5077",
            "b3f089cadbc64b309452463746a06958",
            "5184fbef127a4956aad274267124b5a6",
            "3628ccbff98143cbb7c74d051fd4545a",
            "89f2d30b17d44c4ba3eae840aac3275e",
            "bc0e3c997e1040bbb32ab0f7337d8367",
            "1ad17b7acf7d4fdb82813faf7f323f56",
            "b71f158b74a04b39a93fe2dbb9565665",
            "0de343dd5d61415bba8f9bacc9b9014a",
            "245b4bb7f82b4e87840b79e930cb5bb9",
            "06d8a4a8586746cba2f97b7e5bc4923b",
            "e2c5de2a1d1641f59dc828adb8d4f916",
            "eafc821b115e41549abc20876ed50d41",
            "3016eb9b17274257b388e3fa416293e2",
            "2a229bd6b3a848a89f0f1ef51fc35aa3",
            "05592fe8dc854e9b80677a05e08a6793",
            "7812e46862374d179bb2e982c7ba4fd9",
            "acd09034fd9d48a1a3214ff40a048c5f",
            "30025d31d0fa437391a7c1b06255a76e",
            "a97c2f4ba38248c3826f7d9906ce2577",
            "8aae1e86310e43bc812e38aafaef75e0",
            "ad56a032ccea4a55bdfc412ade9097c8",
            "6f00921616e345cd81334406a0c5f5c2",
            "17fa96c0a7404965b91d8039a8d6ee59",
            "66fe3b76d3a04227a65ab03a301ffc1d",
            "6abdf39855a94856aef23f01abded812",
            "2ad6d079e67c4ec281a95d7c8b27c749",
            "bfc2ddc5257643ec95fcff86bce90903",
            "45f16e7245d54b579924dd981f173d94",
            "3e8f2fca0aa442388b654527960d1421",
            "79f03663eb0d4ca5b3daad423068426d",
            "c2c3b26cda834b24b1b53f15318d1742",
            "d289880dfa2744ae97824cfb75de490a",
            "9a7e8a9c38164ea2aa3d7705900ccf91",
            "2f7d0a4db1cf4c8497dcb279fb0fc2a5",
            "1bbe16479559429c97d9e99a7ad326cf"
          ]
        },
        "outputId": "96374b7a-f5fa-424e-85e7-ca126c1605f8"
      },
      "source": [
        "# Si estamos utilizando google colab, no se preocupen por las descargas, ya que las hace el servidor de colab y no les gasta ancho de banda a uds\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # Cargamos el tokenizador\n",
        "model = BertModel.from_pretrained('bert-base-uncased') # Cargamos el modelo pre-entrenado"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc31fde107e647469506dafa23f5e217"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3628ccbff98143cbb7c74d051fd4545a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a229bd6b3a848a89f0f1ef51fc35aa3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6abdf39855a94856aef23f01abded812"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwxJlH5Vc914",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39356a39-f326-4dda-a597-17978eb8d08d"
      },
      "source": [
        "# 'pt' especifica que queremos vectores de pytorch, 'tf' seria en tensorflow\n",
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\") \n",
        "# el doble asterico ayuda a evaluar los valores de un diccionario, por ejemplo:\n",
        "# d = {'a': 1, 'b':2}, model(**d) sería equivalente a model(1,2)\n",
        "outputs = model(**inputs)\n",
        "# El ultimo hidden-state es el primer elemento del output del modelo.\n",
        "last_hidden_states = outputs[0].squeeze(0) # squeeze en la primera dimension ya que es 1\n",
        "print(inputs['input_ids']) # Tenemos 8 tokens, contando el CLS (101) y el SEP (102)\n",
        "print(last_hidden_states.shape) # Tenemos 8 vectores de 768 dimensiones\n",
        "print(last_hidden_states)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]])\n",
            "torch.Size([8, 768])\n",
            "tensor([[-0.1144,  0.1937,  0.1250,  ..., -0.3827,  0.2107,  0.5407],\n",
            "        [ 0.5308,  0.3207,  0.3665,  ..., -0.0036,  0.7579,  0.0388],\n",
            "        [-0.4877,  0.8849,  0.4256,  ..., -0.6976,  0.4458,  0.1231],\n",
            "        ...,\n",
            "        [-0.7003, -0.1815,  0.3297,  ..., -0.4838,  0.0680,  0.8901],\n",
            "        [-1.0355, -0.2567, -0.0317,  ...,  0.3197,  0.3999,  0.1795],\n",
            "        [ 0.6080,  0.2610, -0.3131,  ...,  0.0311, -0.6283, -0.1994]],\n",
            "       grad_fn=<SqueezeBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU4iTHzpbBjm"
      },
      "source": [
        "La primera pregunta es... cómo diantres obtengo una representación de mi oración desde el último hidden-state?\n",
        "\n",
        "Las opciones más simples son tomar el token CLS, aunque no es muy recomendado, ya que depende del fine tunning (veremos esto más adelante) y la otra opción es tomar el promedio de todos mis tokens. Hay más formas de pooling (es decir como se mezclan los tokens), por ejemplo, podemos ver las de bert-as-service [acá](https://github.com/hanxiao/bert-as-service#q-what-are-the-available-pooling-strategies)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbmxaTNpeeCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21771445-0a18-44fe-915d-1c73e6a11acd"
      },
      "source": [
        "cantidad_tokens = inputs['input_ids'].shape[1]\n",
        "# Representacion con token cls\n",
        "cls_representation = last_hidden_states[0] # El primer token del ultimo hidden-state es el CLS\n",
        "print(cls_representation.shape) # Representacion de 768 dimensiones\n",
        "\n",
        "# Representacion con average 1 (más verbosa)\n",
        "average = torch.zeros(768)\n",
        "for i in range(1, cantidad_tokens-1): # Partimos en 1 y terminamos en largo-2 para ignorar CLS y SEP\n",
        "  average += last_hidden_states[i] \n",
        "average = average/(cantidad_tokens-2) # Obtenemos nuestra representacion de 768 dimensiones\n",
        "print(average.shape)\n",
        "\n",
        "# Representacion con average 2 (más corta)\n",
        "average2 = torch.mean(last_hidden_states[1:-1], 0)\n",
        "print(average2.shape)\n",
        "print(torch.equal(average, average2))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Noj-NgUarIXt"
      },
      "source": [
        "## Ok, pero puedo representar oraciónes con BERT, puedo hacer algo más a parte de eso o se acabó la diversión?\n",
        "\n",
        "¡Esto es solo el principio! ¡La librería transformers a parte nos presta modelos con decoders fine-tuneados en ciertas tareas y hasta podemos fine-tunearlos nosotros!\n",
        "\n",
        "Fine-tunear ayuda a que BERT entienda cual es la tarea que queremos resolver. El modelo de por sí ya viene pre-entrenado en las 2 tareas que mencione previamente, Masked Language Modeling y Next Sentence Prediction sobre corpus muy grandes. \n",
        "\n",
        "Hay 2 modelos pre-entrenados de BERT: bert-base y bert-large que difieren en el tamaño del modelo, pero fueron entrenados sobre el mismo corpus: Wikipedia en ingles, además de aproximadamente 11.000 libros en ingles (esto se llama BookCorpus).\n",
        "\n",
        "bert-base tiene 12 layers (transformer blocks), 12 attention heads, y 110 millones de parametros\n",
        "\n",
        "bert-large tiene 24 layers (transformer blocks), 16 attention heads, y 340 millones de parametros\n",
        "\n",
        "Una vez hice el cálculo rápido de cuanto me saldría entrenar bert-base desde cero en las cloud TPU de Google y era una cifra cercana a los 2000 dólares. Por suerte aquí tenemos a alguien que lo entrenó en español y nos puede contar su experiencia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3in0Nv1fZ9N"
      },
      "source": [
        "\n",
        "## Gabriel y BETO\n",
        "\n",
        "Experiencia de Gabriel y BETO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbgGNC8bsOp3"
      },
      "source": [
        "Continuando con los ejemplos, veamos como sería utilizar BertForNextSentencePrediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5Hgj5mtszxF"
      },
      "source": [
        "from transformers import BertForNextSentencePrediction"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiREjwJXs_J_"
      },
      "source": [
        "Utilizamos el tokenizador común de BERT, solo cambiamos el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fImmBe-es7MS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec472cf-2d34-4eae-9745-8a9329a21b76"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA1PyIHxtEl3"
      },
      "source": [
        "Creemos una función que nos dice si tiene sentido o no la oración que continua."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykgyF3hrtSes"
      },
      "source": [
        "def evaluar_oraciones(primera,segunda):\n",
        "  encoding = tokenizer(primera, segunda, return_tensors='pt')\n",
        "  outputs = model(**encoding, labels=torch.LongTensor([1])) # El label representa cual es la oración\n",
        "  #Nota logits[0,0] entrega el score que la oracion si sea la siguiente (que tan True)\n",
        "  #logits[0,1] entrega el score de que la oracion no sea la siguiente (que tan False)\n",
        "  # Se puede aplicar una SoftMax sobre estos resultados para que sean probabilidades\n",
        "  # Pero no es necesario.\n",
        "  #return outputs\n",
        "  if outputs.logits[0,0] < outputs.logits[0,1]:\n",
        "    print(\"La oración no tiene nada que ver\")\n",
        "  elif outputs.logits[0,0] > outputs.logits[0,1]:\n",
        "    print(\"La oración es una continuación\")\n",
        "  else:\n",
        "    print(\"No estoy seguro\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-RxdXlvuPW9"
      },
      "source": [
        "Probemos este código con algunos ejemplos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNNxshA5tK8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9fc409f-242a-4554-c50a-d06ac4183675"
      },
      "source": [
        "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
        "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
        "evaluar_oraciones(prompt,next_sentence)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La oración no tiene nada que ver\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QWK8kC0ujfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b1d8186-d7c5-40d9-c6a3-cce3d8604058"
      },
      "source": [
        "prompt = \"I'm really hungry.\"\n",
        "next_sentence = \"I'm getting a BigMac.\"\n",
        "evaluar_oraciones(prompt,next_sentence)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La oración es una continuación\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IziEtXRvs0i"
      },
      "source": [
        "## Esto funciona bastante bien, que pasa si quiero entrenarlo para una tarea en especifico?\n",
        "\n",
        "Para esto debemos fine-tunear el modelo con nuestros datos. Tomé [este](https://medium.com/swlh/painless-fine-tuning-of-bert-in-pytorch-b91c14912caa) tutorial como referencia por si algún paso no queda lo suficientemente claro. Vamos a fine-tunear BERT para realizar sentiment classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecFw688fxbVE"
      },
      "source": [
        "Lo primero es inicializar un modelo de BERT sin fine-tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go2YCpqZxmBi"
      },
      "source": [
        "from transformers import BertModel"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2mMoB7qxiTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c648acc-04f7-4610-be4d-8c1bc0c1fd7f"
      },
      "source": [
        "#Creamos un modelo de BERT limpio\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "#El mismo tokenizador de antes\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IONb3bWNxBi4"
      },
      "source": [
        "Debemos entender como se le pasan los datos a BERT. Imaginemos que queremos agregar varias oraciones simultaneamente. Como lo hacemos con tensores si tienen largo distinto? La solucion a esto se llama padding, es decir agregar tokens para que todas las secuencias tengan el mismo largo. \\\n",
        "Pero esto podría traer problemas si es que BERT llegase a interpretar estos tokens como partes de la oración verdad? Para eso es que es necesario especificarle a BERT cuales son los tokens a los que les tiene que tomar atención.\n",
        "\n",
        "Por ejemplo, si tuviesemos un largo máximo de 12 tokens, para padear la oración 'I really enjoyed this movie a lot.' hariamos lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sVnR_TOw9e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b5d6a4-6374-4024-c01b-9c1a4c33c874"
      },
      "source": [
        "#Largo maximo de los tokens\n",
        "T = 12\n",
        "sentence = 'I really enjoyed this movie a lot.'\n",
        "#Step 1: Tokenizar\n",
        "tokens = tokenizer.tokenize(sentence) # ['i', 'really', 'enjoyed', 'this', 'movie', 'a', 'lot', '.']\n",
        "#Step 2: Agregar [CLS] y [SEP]\n",
        "tokens = ['[CLS]'] + tokens + ['[SEP]'] # ['[CLS]','i', 'really', 'enjoyed', 'this', 'movie', 'a', 'lot', '.', '[SEP]']\n",
        "#Step 3: Padear tokens\n",
        "padded_tokens = tokens + ['[PAD]' for _ in range(T - len(tokens))] #    ['[CLS]','i', 'really', 'enjoyed', 'this', 'movie', 'a', 'lot', '.', '[SEP]', '[PAD]', ... , '[PAD]']\n",
        "attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens] # [    1  , 1 ,    1    ,    1     ,   1   ,    1   ,  1 ,   1  ,  1 ,   1    ,    0   , ... ,    0   ] \n",
        "#Step 4: Segment ids: Estos representan cuando tienes 2 oraciones, la primera se llena con 0's y la segunda con 1's\n",
        "seg_ids = [0 for _ in range(len(padded_tokens))] # En este caso no la usaremos, ya que es solo 1 oración. Su representacion son solo 0's\n",
        "#Step 5: Cambiamos los tokens por su respectivo numero, CLS = 101, SEP = 102, etc...\n",
        "token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
        "\n",
        "#Los cambiamos a tensores de pytorch antes de que entren al modelo, y es necesario agregarles una dimension extra.\n",
        "# Esta dimension representa cuantas oraciones estamos pasando\n",
        "token_ids = torch.tensor(token_ids).unsqueeze(0) #Shape : [1, 12]\n",
        "attn_mask = torch.tensor(attn_mask).unsqueeze(0) #Shape : [1, 12]\n",
        "seg_ids   = torch.tensor(seg_ids).unsqueeze(0) #Shape : [1, 12]\n",
        "\n",
        "#Y al igual que antes podemos pasarselos a BERT\n",
        "outputs= bert_model(token_ids, attention_mask = attn_mask, token_type_ids = seg_ids)\n",
        "#outputs\n",
        "print(outputs.last_hidden_state.shape)\n",
        "#Out: torch.Size([1, 12, 768])\n",
        "print(outputs.pooler_output.shape)\n",
        "#Out: torch.Size([1, 768])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 12, 768])\n",
            "torch.Size([1, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1853-AW09Up"
      },
      "source": [
        "No está de más agregar que BERT tiene un maximo de 512 tokens por input, por lo que si queremos agregar un texto muy grande debemos o truncarlo o separarlo en 2.\\\n",
        "Ahora que aprendimos como paddear oraciones, utilizaremos el Stanford Sentiment Tree Bank dataset que contiene movie reviews con sentimiento positivo (1) y negativo (0).\\\n",
        "Primero crearemos una clase para cargar los datos, extendiendo la clase Dataset que viene con pytorch:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1q9tjbz1tm4"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "class SSTDataset(Dataset):\n",
        "    # Inicializacion de la clase\n",
        "    def __init__(self, filename, maxlen):\n",
        "        #Guardar los contenidos del dataframe\n",
        "        self.df = pd.read_csv(filename, delimiter = '\\t')\n",
        "        #Initialize the BERT tokenizer\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        # Establecer el largo máximo\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    # Funcion auxiliar que retorna el largo del dataframe\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #Seleccionamos la oracion y el label de este dataset en especifico.\n",
        "        sentence = self.df.loc[index, 'sentence']\n",
        "        label = self.df.loc[index, 'label']\n",
        "\n",
        "        #Realizamos todo el pre-procesamiento que explicamos anteriormente\n",
        "        tokens = self.tokenizer.tokenize(sentence)\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "        if len(tokens) < self.maxlen: # Comparamos con la cantidad maxima de tokens que dimos\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] # Si es mas corta agregamos padding\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]']  # Si es mas larga la cortamos\n",
        "\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Utilizamos el tokenizador para pasarlos a id\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids) #Pasamos a tensor de pytorch\n",
        "\n",
        "        #1 para los tokens no padeados, 0 si es padding\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVwxAu893Swd"
      },
      "source": [
        "Creamos los dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0WWC2Be3UtV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b8ad096-c815-4e99-b6f6-24c00a73049a"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Creamos instancias del training y validation sets\n",
        "train_set = SSTDataset(filename = '/content/train.tsv', maxlen = 30)\n",
        "val_set = SSTDataset(filename = '/content/dev.tsv', maxlen = 30)\n",
        "\n",
        "#Creamos los dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size = 64, num_workers = 5)\n",
        "val_loader = DataLoader(val_set, batch_size = 64, num_workers = 5)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIHYBYjP38X3"
      },
      "source": [
        "Ahora la parte más importante, generar nuestro modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beYZGXu_4BAy"
      },
      "source": [
        "import torch.nn as nn\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, freeze_bert = True):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        #Creamos una instancia de BERT sin entrenamiento previo\n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased').cuda()\n",
        "        \n",
        "        #Con esto podemos bloquear el entrenamiento de BERT, para comparar incluyendo el entrenamiento de bert y sin\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer.parameters():\n",
        "                p.requires_grad = False\n",
        "        \n",
        "        #La capa para clasificar\n",
        "        #La idea es transformar una representacion de BERT (768 dimensiones) en 1 o 0 que representa el sentimiento\n",
        "        self.cls_layer = nn.Linear(768, 1).cuda()\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        '''\n",
        "        Inputs:\n",
        "            seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "        '''\n",
        "        #Le pasamos el input al modelo BERT\n",
        "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
        "\n",
        "        #Obtenemos la representacion del token CLS\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "\n",
        "        #Pasamos el token CLS por la capa de clasificacion\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkRDKgHj496y"
      },
      "source": [
        "Utilizaremos binary cross-entropy loss y un descenso de gradiente estocastico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7lXDEbk5OAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3267f064-c951-4aac-899a-10be854e91f6"
      },
      "source": [
        "import torch.optim as optim\n",
        "#Creamos el classificador de sentimiento basado en BERT\n",
        "net_freezed = SentimentClassifier(freeze_bert = True)\n",
        "net_not_freezed = SentimentClassifier(freeze_bert = False)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "opti_freezed = optim.Adam(net_freezed.parameters(), lr = 2e-5)\n",
        "opti_not_freezed = optim.Adam(net_not_freezed.parameters(), lr = 2e-5)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf2qL53wBN3_"
      },
      "source": [
        "Agregamos funciones axuliares para medir el desempeño del entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6Vk-syTBSUb"
      },
      "source": [
        "def get_accuracy_from_logits(logits, labels):\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "    soft_probs = (probs > 0.5).long()\n",
        "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
        "    return acc\n",
        "    \n",
        "def evaluate(net, criterion, dataloader):\n",
        "    net.eval() # Modo evaluacion del modelo, pesos no serán modificados\n",
        "    mean_acc, mean_loss = 0, 0\n",
        "    count = 0\n",
        "    with torch.no_grad(): # Los gradientes no serán guardados tampoco\n",
        "        for seq, attn_masks, labels in dataloader:\n",
        "            seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "            logits = net(seq, attn_masks)\n",
        "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
        "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
        "            count += 1\n",
        "\n",
        "    return mean_acc / count, mean_loss / count"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT0-p2BE5c-T"
      },
      "source": [
        "Y con la siguiente funcion entrenamos los parametros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32HzrhSG5euh"
      },
      "source": [
        "def train(net, criterion, opti, train_loader, val_loader, epochs):\n",
        "    for ep in range(epochs): # Iterador de las epocas\n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            #Clear gradients\n",
        "            opti.zero_grad()  \n",
        "            #Enviamos los tensores a la GPU\n",
        "            seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "\n",
        "            #Evaluamos nuestro modelo en la secuencia y la mask de atencion\n",
        "            logits = net(seq, attn_masks)\n",
        "\n",
        "            #Calculamos la loss\n",
        "            loss = criterion(logits.squeeze(-1), labels.float())\n",
        "\n",
        "            #Backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            #Optimization step\n",
        "            # Ojo que si no tenemos freeze_bert en true, vamos a entrenar los parametros de bert tambien.\n",
        "            opti.step()\n",
        "\n",
        "            if (it + 1) % 100 == 0:\n",
        "                acc = get_accuracy_from_logits(logits, labels)\n",
        "                print(\"Iteration {} of epoch {} complete. Loss : {} Train Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
        "        val_acc, val_loss = evaluate(net, criterion, val_loader)\n",
        "        print(\"Epoch {} complete! Validation Accuracy : {}, Validation Loss : {}\".format(ep+1, val_acc, val_loss))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsXNXjQY6aKt"
      },
      "source": [
        "Y finalmente entrenamos ambos modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcMLMjiz6ccC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "b9336eb6-36b4-4e8e-b04f-f839bc8eb68c"
      },
      "source": [
        "epochs = 5\n",
        "train(net_freezed, criterion, opti_freezed, train_loader, val_loader, epochs)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-3dd91bf9dcf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_freezed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti_freezed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-51ac872ecc6d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, criterion, opti, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m#Evaluamos nuestro modelo en la secuencia y la mask de atencion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m#Calculamos la loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-cb247a7a173b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq, attn_masks)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#Obtenemos la representacion del token CLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mcls_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcont_reps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#Pasamos el token CLS por la capa de clasificacion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxBUZUC6d1jC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "4d07370e-c782-4b0a-8d5d-23ef46f0794b"
      },
      "source": [
        "train(net_not_freezed, criterion, opti_not_freezed, train_loader, val_loader, epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 100 of epoch 1 complete. Loss : 0.2919929623603821 Train Accuracy : 0.890625\n",
            "Iteration 200 of epoch 1 complete. Loss : 0.4610022008419037 Train Accuracy : 0.796875\n",
            "Iteration 300 of epoch 1 complete. Loss : 0.3382772207260132 Train Accuracy : 0.875\n",
            "Iteration 400 of epoch 1 complete. Loss : 0.14136575162410736 Train Accuracy : 0.921875\n",
            "Iteration 500 of epoch 1 complete. Loss : 0.0685427188873291 Train Accuracy : 0.984375\n",
            "Iteration 600 of epoch 1 complete. Loss : 0.15615978837013245 Train Accuracy : 0.921875\n",
            "Iteration 700 of epoch 1 complete. Loss : 0.2990710735321045 Train Accuracy : 0.875\n",
            "Iteration 800 of epoch 1 complete. Loss : 0.06944824755191803 Train Accuracy : 0.984375\n",
            "Iteration 900 of epoch 1 complete. Loss : 0.13161134719848633 Train Accuracy : 0.96875\n",
            "Iteration 1000 of epoch 1 complete. Loss : 0.12836754322052002 Train Accuracy : 0.96875\n",
            "Epoch 1 complete! Validation Accuracy : 0.9058035612106323, Validation Loss : 0.25508606327431543\n",
            "Iteration 100 of epoch 2 complete. Loss : 0.07849311828613281 Train Accuracy : 0.953125\n",
            "Iteration 200 of epoch 2 complete. Loss : 0.16527271270751953 Train Accuracy : 0.96875\n",
            "Iteration 300 of epoch 2 complete. Loss : 0.2586386203765869 Train Accuracy : 0.921875\n",
            "Iteration 400 of epoch 2 complete. Loss : 0.044397495687007904 Train Accuracy : 0.984375\n",
            "Iteration 500 of epoch 2 complete. Loss : 0.06985306739807129 Train Accuracy : 0.984375\n",
            "Iteration 600 of epoch 2 complete. Loss : 0.054696738719940186 Train Accuracy : 0.984375\n",
            "Iteration 700 of epoch 2 complete. Loss : 0.16971246898174286 Train Accuracy : 0.953125\n",
            "Iteration 800 of epoch 2 complete. Loss : 0.005608794279396534 Train Accuracy : 1.0\n",
            "Iteration 900 of epoch 2 complete. Loss : 0.02981206402182579 Train Accuracy : 0.984375\n",
            "Iteration 1000 of epoch 2 complete. Loss : 0.08376139402389526 Train Accuracy : 0.96875\n",
            "Epoch 2 complete! Validation Accuracy : 0.9035714268684387, Validation Loss : 0.2673555479518005\n",
            "Iteration 100 of epoch 3 complete. Loss : 0.024941155686974525 Train Accuracy : 1.0\n",
            "Iteration 200 of epoch 3 complete. Loss : 0.07665261626243591 Train Accuracy : 0.953125\n",
            "Iteration 300 of epoch 3 complete. Loss : 0.24904902279376984 Train Accuracy : 0.9375\n",
            "Iteration 400 of epoch 3 complete. Loss : 0.055118151009082794 Train Accuracy : 0.984375\n",
            "Iteration 500 of epoch 3 complete. Loss : 0.004846522118896246 Train Accuracy : 1.0\n",
            "Iteration 600 of epoch 3 complete. Loss : 0.017122505232691765 Train Accuracy : 1.0\n",
            "Iteration 700 of epoch 3 complete. Loss : 0.10792330652475357 Train Accuracy : 0.953125\n",
            "Iteration 800 of epoch 3 complete. Loss : 0.0024116889107972383 Train Accuracy : 1.0\n",
            "Iteration 900 of epoch 3 complete. Loss : 0.004038392566144466 Train Accuracy : 1.0\n",
            "Iteration 1000 of epoch 3 complete. Loss : 0.09052665531635284 Train Accuracy : 0.953125\n",
            "Epoch 3 complete! Validation Accuracy : 0.8991071581840515, Validation Loss : 0.294412513928754\n",
            "Iteration 100 of epoch 4 complete. Loss : 0.0038735780399292707 Train Accuracy : 1.0\n",
            "Iteration 200 of epoch 4 complete. Loss : 0.020893648266792297 Train Accuracy : 0.984375\n",
            "Iteration 300 of epoch 4 complete. Loss : 0.12112196534872055 Train Accuracy : 0.96875\n",
            "Iteration 400 of epoch 4 complete. Loss : 0.028255373239517212 Train Accuracy : 0.984375\n",
            "Iteration 500 of epoch 4 complete. Loss : 0.003907563164830208 Train Accuracy : 1.0\n",
            "Iteration 600 of epoch 4 complete. Loss : 0.01481613703072071 Train Accuracy : 1.0\n",
            "Iteration 700 of epoch 4 complete. Loss : 0.06262359768152237 Train Accuracy : 0.953125\n",
            "Iteration 800 of epoch 4 complete. Loss : 0.0021003049332648516 Train Accuracy : 1.0\n",
            "Iteration 900 of epoch 4 complete. Loss : 0.00777034368366003 Train Accuracy : 1.0\n",
            "Iteration 1000 of epoch 4 complete. Loss : 0.01746947318315506 Train Accuracy : 1.0\n",
            "Epoch 4 complete! Validation Accuracy : 0.8881696462631226, Validation Loss : 0.4397291157926832\n",
            "Iteration 100 of epoch 5 complete. Loss : 0.00885507371276617 Train Accuracy : 1.0\n",
            "Iteration 200 of epoch 5 complete. Loss : 0.053689926862716675 Train Accuracy : 0.96875\n",
            "Iteration 300 of epoch 5 complete. Loss : 0.1083274558186531 Train Accuracy : 0.96875\n",
            "Iteration 400 of epoch 5 complete. Loss : 0.025958016514778137 Train Accuracy : 0.984375\n",
            "Iteration 500 of epoch 5 complete. Loss : 0.001841120421886444 Train Accuracy : 1.0\n",
            "Iteration 600 of epoch 5 complete. Loss : 0.004323156550526619 Train Accuracy : 1.0\n",
            "Iteration 700 of epoch 5 complete. Loss : 0.02931322529911995 Train Accuracy : 0.984375\n",
            "Iteration 800 of epoch 5 complete. Loss : 0.005530685186386108 Train Accuracy : 1.0\n",
            "Iteration 900 of epoch 5 complete. Loss : 0.001964530674740672 Train Accuracy : 1.0\n",
            "Iteration 1000 of epoch 5 complete. Loss : 0.0035197387915104628 Train Accuracy : 1.0\n",
            "Epoch 5 complete! Validation Accuracy : 0.8857142925262451, Validation Loss : 0.42530072799750734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giFhU398k17w"
      },
      "source": [
        "Comparando ambos entrenamientos, pasamos de 82% a 88% en 5 epocas. El primer entrenamiento solo entrenamos la capa de clasificacion mientras que en el segundo tambien modificamos los parametros de BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exBniyWo8Ni9"
      },
      "source": [
        "Este ultimo entrenamiento es lo que llamamos fine-tunning. Lo más importante de esto es que no necesitamos un super computador para poder mejorar las representaciones en una tarea especifica."
      ]
    }
  ]
}