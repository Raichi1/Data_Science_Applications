{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "PmozbMh5CEAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 align=\"center\"><b>TA1:</b> NLP - Normalización de textos </h3>\n",
        "<h3 align=\"center\">2023-2</h3>\n"
      ],
      "metadata": {
        "id": "527lRI0zDtC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Nombre del Alumno: Renzo Andre Espíritu Cueva**\n",
        "\n",
        "**Código: u202113340**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bfWr1IM-DMap"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYdJ6qZIwWnQ"
      },
      "source": [
        "### **NLP: Normalización de textos y Bolsa de Palabras**\n",
        "\n",
        "* El corpus que se normalizará consiste en una serie de artículos obtenidos de la web \"https://www.elmundotoday.com/\".\n",
        "\n",
        "\n",
        "* Estos artículos se encuentran en el fichero csv **corpus_mundo_today.csv** que deberá adjuntar al notebook.\n",
        "\n",
        "\n",
        "* Este CSV esta formado por 3 campos que son:\n",
        "    - Tema\n",
        "    - Título\n",
        "    - Texto\n",
        "    \n",
        "    \n",
        "* El ejercicio consiste en Normalizar este ***Corpus*** tomando el *título* y *texto* como contenido de cada documento.\n",
        "\n",
        "Puede utilizar indistintamente las librerias **NLTK** y **Spacy** para el preprocesamiento (normalización) del texto.\n",
        "\n",
        "\n",
        "## Ejercicios de Nomalización solicitados:\n",
        "\n",
        "* Dada una lista en la que cada elemento de la misma tiene el contenido (título + texto) de cada documento del corpus se pide:\n",
        "<span></span><br><br>\n",
        "    1. **Crear una función que devuelva los documentos *Tokenizados* (una lista de listas) y con los tokens (palabras) en minúsculas.**\n",
        "        * **input**: lista de documentos (lista de Strings).\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "<span></span><br><br>\n",
        "    2. **Crear una función que elimine los tokens que sean signos de puntuación y *Stop-Words*.**\n",
        "        * **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "<span></span><br><br>\n",
        "    3. **Crear una función que transforme cada token a su lema (*Lematización*)**\n",
        "        * **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "<span></span><br><br>\n",
        "    4. **Crear una función que elimine todos los tokens que no sean *Nombres* (NOUN, PROPN), *Verbos*, *Advervios* o *Adjetivos*.**\n",
        "        * **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        " <span></span><br><br>       \n",
        "    5. **Función que dada una lista de documentos, devuelva los documentos normalizados. Este ejercicio ya esta hecho y simplemente tiene que funcionar llamando a las 4 funciones anteriores.**\n",
        "        * **input**: lista de documentos (lista de Strings).\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento normalizados.\n",
        "\n",
        "\n",
        "* Finalizada la normalización anterior, se pide:\n",
        "\n",
        "    6. **Crear una función que dada una lista de documentos (*corpus*) tokenizados, elimine del corpus aquellos tokens que aparecen menos de 'N' veces (N=10) en el corpus**\n",
        "        * **input**: lista de listas, en la que cada lista contiene los tokens del documento normalizados.\n",
        "        * **input**: 'N' -> Parámetro que nos indica el número mínimo de apariciones de la palabra en el corpus.\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento normalizados.\n",
        "<span></span><br><br>\n",
        "   \n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv6qkBgRwWnX"
      },
      "source": [
        "## Ejercicios de Nomalización:\n",
        "\n",
        "* Leemos el corpus y pasamos los documentos (Título + Texto) a una lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtvRq_btwWnY"
      },
      "outputs": [],
      "source": [
        "docs_file = 'corpus_mundo_today.csv'\n",
        "docs_list = list()\n",
        "file_txt = open(docs_file, encoding=\"utf8\").read()\n",
        "for line in file_txt.split('\\n'):\n",
        "    line = line.split('||')\n",
        "    docs_list.append(line[1] + ' ' + line[2])\n",
        "docs_list = docs_list[1:] # Elimino la cabecera del fichero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7A1rAYSwWna"
      },
      "source": [
        "#### 1. **Crear una función que devuelva los documentos *Tokenizados* (una lista de listas) y con los tokens (palabras) en minúsculas.** (3ptos)\n",
        "\n",
        "* **input**: lista de documentos (lista de Strings).\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFW19aYOpWMk",
        "outputId": "2ae07c05-b91b-4679-f5e2-d412d8f011d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re"
      ],
      "metadata": {
        "id": "heH8aIfch-ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2jmTvEgpS9R",
        "outputId": "42adcebb-9f23-4e88-963a-98d2e6ead27e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-4TOCb_wWnb"
      },
      "outputs": [],
      "source": [
        "def tokenization(docs_list):\n",
        "    tokens = [word_tokenize(string.lower()) for string in docs_list]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJTRkdaNwWnb"
      },
      "source": [
        "#### 2. **Crear una función que elimine los tokens que sean signos de puntuación y *Stop-Words*.** (3ptos)\n",
        "\n",
        "* **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_Zij4h5wWnc"
      },
      "outputs": [],
      "source": [
        "def remove_words(docs):\n",
        "    stop_words = set(stopwords.words('spanish'))  # Puedes cambiar 'spanish' por el idioma que necesites\n",
        "    sign_punct = set(string.punctuation)\n",
        "    sign_com = {'“','”'}\n",
        "\n",
        "    doc_result = []\n",
        "\n",
        "    for doc in docs:\n",
        "        tokens = [token for token in doc if token not in stop_words and token not in sign_punct and token not in sign_com and not re.match(r'^[\\d\\-.]+$', token) and len(token) > 2 ]\n",
        "\n",
        "        doc_result.append(tokens)\n",
        "\n",
        "    return doc_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVZeM62QwWnd"
      },
      "source": [
        "#### 3. **Crear una función que transforme cada token a su lema (*Lematización*)** (3ptos)\n",
        "\n",
        "* **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEtGUMxUwWnd"
      },
      "outputs": [],
      "source": [
        "def lematization(docs):\n",
        "    nlp = spacy.load('es_core_news_md')\n",
        "    lem_result = []\n",
        "    for toks in docs:\n",
        "        doc_str = ' '.join(toks)\n",
        "        doc = nlp(doc_str)\n",
        "        lemas = [token.lemma_ for token in doc]\n",
        "        lem_result.append(lemas)\n",
        "    return lem_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdz8mIcCwWne"
      },
      "source": [
        "#### 4. **Crear una función que elimine todos los tokens que no sean *Nombres* (NOUN, PROPN), *Verbos*, *Advervios* o *Adjetivos*.** (4ptos)\n",
        "\n",
        "* **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4v5aGv5wWne"
      },
      "outputs": [],
      "source": [
        "def filter_words(docs):\n",
        "    nlp = spacy.load('es_core_news_md')\n",
        "    doc_filter = []\n",
        "    for documento_tokens in docs:\n",
        "        doc_str = ' '.join(documento_tokens)\n",
        "        doc = nlp(doc_str)\n",
        "        tok_filter = [token.lemma_ for token in doc if token.pos_ in {'NOUN', 'PROPN', 'VERB', 'ADV', 'ADJ'}]\n",
        "        doc_filter.append(tok_filter)\n",
        "    return doc_filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0h29B0IwWne"
      },
      "source": [
        "#### 5. **Función que dada una lista de documentos, devuelva los documentos normalizados. Este ejercicio ya esta hecho y simplemente tiene que funcionar llamando a las 4 funciones anteriores.** (3ptos)\n",
        "\n",
        "* **input**: lista de documentos (lista de Strings).\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento normalizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rzYM9jRwWnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85099634-9734-43bd-bfc4-6363ae6189c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gobierno', 'español', 'sumar', 'condena', 'cumplir', 'puigdemont', 'después', 'revés', 'recibido', 'gobierno', 'españa', 'puesta', 'libertad', 'car', 'puigdemont', 'parte', 'justicia', 'alemán', 'juez', 'pablo', 'llarena', 'decidido', 'semana', 'instancia', 'ejecutivo', 'sumar', 'oriol', 'condena', 'cumplir', 'líder', 'pdecat', 'exvicepresidente', 'cataluña', 'permanecer', 'prisión', 'madrileño', 'pasar', 'noviembre', 'asumir', 'delito', 'atribuido', 'car', 'puigdemont', 'manerar', 'tribunal', 'supremo', 'asegurar', 'acto', 'expresidente', 'catalán', 'última', 'legislatura', 'quedar', 'impún', 'pagar', 'maniobra', 'ideado', 'burlar', 'justicia', 'alemán', 'líder', 'esquerra', 'republicano', 'enfrentar', 'año', 'prisión', 'seguir', 'adelante', 'caer', 'año', 'parar', 'dicho', 'hoy', 'car', 'puigdemont', 'alemania', 'hacer', 'hacer', 'sacrificar', 'asumire', 'resignación', 'determinación', 'prometido', 'seguim', 'tuitear', 'después', 'trascender', 'decisión', 'llarén', 'fuente', 'anónimo', 'poder', 'judicial', 'barajar', 'posibilidad', 'añadir', 'pena', 'oriol', 'condena', 'imponer', 'futuro', 'iñaki', 'urdangarin', 'rodrigo', 'rato', 'esperanza', 'aguirre', 'así', 'delito', 'robo', 'fuerza', 'ocurrido', 'hacer', 'semana', 'huesca', 'policía', 'incapaz', 'encontrar', 'culpable']\n"
          ]
        }
      ],
      "source": [
        "def normalization(docs_list):\n",
        "    corpus = tokenization(docs_list)\n",
        "    corpus = remove_words(corpus)\n",
        "    corpus = lematization(corpus)\n",
        "    corpus = filter_words(corpus)\n",
        "    return corpus\n",
        "\n",
        "corpus = normalization(docs_list)\n",
        "print(corpus[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### En este ejercicio podemos ver como reducimos las palabras (tokens) del texto original, quedandonos con lo importante y normalizado"
      ],
      "metadata": {
        "id": "QqLNb64MO9G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_list(list_of_lists):\n",
        "  fl_list = []\n",
        "  for ls in list_of_lists:\n",
        "    for tk in ls:\n",
        "      fl_list.append(tk)\n",
        "  return fl_list"
      ],
      "metadata": {
        "id": "_m9k7326rK7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Número de tokens del texto original: ' + str(len(flatten_list(tokenization(docs_list)))))\n",
        "print('Número de tokens distintos del texto original: ' + str(len(set(flatten_list(tokenization(docs_list))))))\n",
        "print('Número de tokens tras la normalización: ' + str(len(normalization(docs_list)[0])))\n",
        "print('Número de tokens distintos tras la normalización: ' + str(len(set(normalization(docs_list)[0]))))"
      ],
      "metadata": {
        "id": "afbcAZB-PLwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812bd21f-def3-458e-da0f-5ba970d4a457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de tokens del texto original: 1345\n",
            "Número de tokens distintos del texto original: 38\n",
            "Número de tokens tras la normalización: 119\n",
            "Número de tokens distintos tras la normalización: 98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6NzHFCMwWnf"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### 6. **Crear una función que dada una lista de documentos (*corpus*) tokenizados, elimine del corpus aquellos tokens que aparecen menos de 'N' veces (N=10) en el corpus** (4ptos)\n",
        "\n",
        "* **input**: lista de listas, en la que cada lista contiene los tokens del documento normalizados.\n",
        "* **input**: 'N' -> Parámetro que nos indica el número mínimo de apariciones de la palabra en el corpus.\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento normalizados."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "a5vVtxT3u6aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogj3An3ywWnf"
      },
      "outputs": [],
      "source": [
        "def drop_less_frecuency_words(corpus, n):\n",
        "    token_freq = Counter()\n",
        "    for document in corpus:\n",
        "        token_freq.update(document)\n",
        "\n",
        "    frequent_tokens = {token for token, freq in token_freq.items() if freq >= n}\n",
        "\n",
        "    filtered_corpus = [[token for token in document if token in frequent_tokens] for document in corpus]\n",
        "\n",
        "    return filtered_corpus\n",
        "\n",
        "corpus = drop_less_frecuency_words(corpus, 10)\n",
        "print(corpus[0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}